{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[1;32m---> 32\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([load_and_preprocess_image_pillow(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m image_paths])\n\u001b[0;32m     33\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([load_and_preprocess_mask_pillow(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m mask_paths])\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Dice Metric\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36mload_and_preprocess_image_pillow\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess_image_pillow\u001b[39m(img_path):\n\u001b[1;32m---> 21\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m192\u001b[39m))\n\u001b[0;32m     22\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     23\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\Lib\\site-packages\\PIL\\Image.py:2345\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2342\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mresize(size, resample, box)\n\u001b[0;32m   2343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m-> 2345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m   2347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reducing_gap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resample \u001b[38;5;241m!=\u001b[39m Resampling\u001b[38;5;241m.\u001b[39mNEAREST:\n\u001b[0;32m   2348\u001b[0m     factor_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m reducing_gap) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:1278\u001b[0m, in \u001b[0;36mTiffImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_load_libtiff:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_libtiff()\n\u001b[1;32m-> 1278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\Lib\\site-packages\\PIL\\ImageFile.py:280\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m         s \u001b[38;5;241m=\u001b[39m read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodermaxblock)\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "\n",
    "# Bild- und Maskenpfade laden\n",
    "image_dir = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Trainingsset/Testbilder2/'\n",
    "mask_dir = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Trainingsset/Testmasken2/'\n",
    "\n",
    "image_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir)])\n",
    "mask_paths = sorted([os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir)])\n",
    "\n",
    "# Funktion zum Laden und Vorverarbeiten der Bilder\n",
    "def load_and_preprocess_image_pillow(img_path):\n",
    "    img = Image.open(img_path).resize((256, 192))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "def load_and_preprocess_mask_pillow(mask_path):\n",
    "    mask = Image.open(mask_path).resize((256, 192))\n",
    "    mask = np.where(np.array(mask) > 128, 1, 0)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return mask\n",
    "\n",
    "X = np.array([load_and_preprocess_image_pillow(path) for path in image_paths])\n",
    "Y = np.array([load_and_preprocess_mask_pillow(path) for path in mask_paths])\n",
    "\n",
    "# Dice Metric\n",
    "def dice_metric(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Benutzerdefinierte Verlustfunktion\n",
    "def combined_loss(y_true, y_pred, smooth=1e-6, binary_weight=0.5, dice_weight=0.5):\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "    dice_loss = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    return binary_weight * bce + dice_weight * dice_loss\n",
    "\n",
    "# U^2-Net spezifische Bl√∂cke\n",
    "def u2net_recurrent_res_block(x, filters):\n",
    "    conv1 = Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(filters, 3, activation='relu', padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    return concatenate([conv1, conv2])\n",
    "\n",
    "def u2net_stage(x, filters):\n",
    "    x1 = u2net_recurrent_res_block(x, filters)\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x2 = u2net_recurrent_res_block(pool, filters * 2)\n",
    "    up = UpSampling2D(size=(2, 2))(x2)\n",
    "    return concatenate([x1, up])\n",
    "\n",
    "def u2net_model(input_size=(192, 256, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Downsampling path\n",
    "    stage1 = u2net_recurrent_res_block(inputs, 64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(stage1)\n",
    "    \n",
    "    stage2 = u2net_recurrent_res_block(pool1, 128)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(stage2)\n",
    "    \n",
    "    stage3 = u2net_recurrent_res_block(pool2, 256)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(stage3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bottleneck = u2net_recurrent_res_block(pool3, 512)\n",
    "    \n",
    "    # Upsampling path\n",
    "    up3 = UpSampling2D(size=(2, 2))(bottleneck)\n",
    "    up3 = Conv2D(256, 3, padding='same', activation='relu')(up3)  # Filter anpassen\n",
    "    up3 = concatenate([up3, stage3], axis=-1)\n",
    "    up3 = u2net_recurrent_res_block(up3, 256)\n",
    "    \n",
    "    up2 = UpSampling2D(size=(2, 2))(up3)\n",
    "    up2 = Conv2D(128, 3, padding='same', activation='relu')(up2)  # Filter anpassen\n",
    "    up2 = concatenate([up2, stage2], axis=-1)\n",
    "    up2 = u2net_recurrent_res_block(up2, 128)\n",
    "    \n",
    "    up1 = UpSampling2D(size=(2, 2))(up2)\n",
    "    up1 = Conv2D(64, 3, padding='same', activation='relu')(up1)  # Filter anpassen\n",
    "    up1 = concatenate([up1, stage1], axis=-1)\n",
    "    up1 = u2net_recurrent_res_block(up1, 64)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(up1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "# K-Fold Validierung\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Modelle/spheroid_segmentation_u2net.h5'\n",
    "epochs = 1000\n",
    "batch_size = 8\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(f\"\\nFold {fold + 1}/{kf.n_splits}\")\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "\n",
    "    model = u2net_model()\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=combined_loss, metrics=[dice_metric])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "    hist = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "    if hist.history['val_loss'][-1] < best_val_loss:\n",
    "        best_val_loss = hist.history['val_loss'][-1]\n",
    "        model.save(best_model_path)\n",
    "\n",
    "history_file = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Modelle/training_history_u2net.json'\n",
    "with open(history_file, 'w') as f:\n",
    "    json.dump(hist.history, f)\n",
    "\n",
    "print(f\"Bestes Modell wurde unter {best_model_path} gespeichert.\")\n",
    "print(f\"Training Historie wurde unter {history_file} gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
