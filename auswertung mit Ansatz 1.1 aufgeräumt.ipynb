{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der geladenen Bilder: 357\n",
      "Form des ersten Bildes: (196, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der TIFF-Dateien: 357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS + P1 C6_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS + P1 C6_ch00.tif, Durchmesser: 159.46 µm, Flächeninhalt: 19580.72 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS + P1 D6_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS + P1 D6_ch00.tif, Durchmesser: 161.25 µm, Flächeninhalt: 20018.14 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS +P1 E6_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS +P1 E6_ch00.tif, Durchmesser: 151.44 µm, Flächeninhalt: 17661.32 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS B4_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS B4_ch00.tif, Durchmesser: 164.50 µm, Flächeninhalt: 20809.00 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS C4_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS C4_ch00.tif, Durchmesser: 163.39 µm, Flächeninhalt: 20529.05 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905ms/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS D4_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + AlPcS D4_ch00.tif, Durchmesser: 154.93 µm, Flächeninhalt: 18494.16 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + P1 B5_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + P1 B5_ch00.tif, Durchmesser: 133.93 µm, Flächeninhalt: 13817.26 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + P1 C5_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + P1 C5_ch00.tif, Durchmesser: 170.45 µm, Flächeninhalt: 22301.48 µm²\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Segmentiertes Bild für 001_CQ Sphaeroide Tag 0 belichtet_2,5% + P1 E5_ch00.tif wurde gespeichert.\n",
      "Bild: 001_CQ Sphaeroide Tag 0 belichtet_2,5% + P1 E5_ch00.tif, Durchmesser: 154.60 µm, Flächeninhalt: 18396.18 µm²\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model  # Import für load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    \n",
    "model_path_1 = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Modelle/spheroid_segmentation_200_trainingsbilder_noch_komplexer_early_stop_and_droput_3.h5'\n",
    "input_dir = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Sphäroide BA/Alle BA Sphäaeroidbilder sortiert'\n",
    "output_dir = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Ergebnisse/Segmentierte_Bilder_mit_dropout_3 beste bisher/'\n",
    "excel_file_path = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Sphäroide BA/gemessene Durchmesser neu.xlsx'\n",
    "excel_output_path_1 = 'C:/Users/chris/Documents/Master/Sphaeroidauswertung/Ergebnisse/Durchmesser Liste mit dropout 3.xlsx'\n",
    "\n",
    "# Skalierungsfaktoren\n",
    "scale_factor_width = 1296 / 256\n",
    "scale_factor_height = 966 / 196\n",
    "\n",
    "\n",
    "\n",
    "def load_and_preprocess_image_pillow(img_path):\n",
    "    img = Image.open(img_path).convert('L')  # Konvertiere zu Graustufen\n",
    "    img = img.resize((196, 256))  # Größe anpassen\n",
    "    img = np.array(img)  # PIL Image zu numpy Array konvertieren\n",
    "    img = img / 255.0  # Normalisierung auf den Bereich [0, 1]\n",
    "    return img\n",
    "\n",
    "\n",
    "# Liste aller Bilddateien im Verzeichnis\n",
    "image_files = [f for f in os.listdir(input_dir) if f.endswith(('.tif', '.png', '.jpg'))]\n",
    "\n",
    "# Laden und Vorverarbeiten der Bilder\n",
    "images = []\n",
    "for filename in image_files:\n",
    "    img_path = os.path.join(input_dir, filename)\n",
    "    image = load_and_preprocess_image_pillow(img_path)  # Korrekte Übergabe des Pfads\n",
    "    if image is not None:\n",
    "        images.append(image)\n",
    "\n",
    "print(f\"Anzahl der geladenen Bilder: {len(images)}\")\n",
    "if len(images) > 0:\n",
    "    print(f\"Form des ersten Bildes: {images[0].shape}\")\n",
    "\n",
    "#excel daten laden\n",
    "predicted_diameters = []\n",
    "df_manual = pd.read_excel(excel_file_path, header=0)  \n",
    "manual_diameters = df_manual.iloc[:, 1].tolist()  \n",
    "\n",
    "#Funktionen\n",
    "def predict_with_model(model1, image):\n",
    "    image = np.expand_dims(image, axis=0)  # Batch-Dimension hinzufügen\n",
    "    predicted_mask = model1.predict(image)  # Vorhersage machen\n",
    "    return np.squeeze(predicted_mask)  # Batch-Dimension entfernen\n",
    "\n",
    "def calculate_average_diameter(contour, center, num_lines=180):\n",
    "    angles = np.linspace(0, 2 * np.pi, num=num_lines, endpoint=False)\n",
    "    diameters = []\n",
    "    for angle in angles:\n",
    "        dx = np.cos(angle)\n",
    "        dy = np.sin(angle)\n",
    "        intersections = []\n",
    "        for i in range(-1000, 1000):\n",
    "            x = int(center[0] + i * dx)\n",
    "            y = int(center[1] + i * dy)\n",
    "            if cv2.pointPolygonTest(contour, (x, y), False) >= 0:\n",
    "                intersections.append((x, y))\n",
    "        if len(intersections) >= 2:\n",
    "            d = np.linalg.norm(np.array(intersections[0]) - np.array(intersections[-1]))\n",
    "            diameters.append(d)\n",
    "    return np.mean(diameters)\n",
    "\n",
    "# Laden und Vorverarbeiten der Bilder mit Pillow\n",
    "\n",
    "\n",
    "# Funktion zur Berechnung der mittleren Konturgröße\n",
    "def calculate_average_contour_size(contour):\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    if perimeter == 0:\n",
    "        return 0\n",
    "    return cv2.contourArea(contour) / perimeter\n",
    "\n",
    "# Funktion zur Auswahl des besten Schwellenwerts\n",
    "def find_best_threshold(mask):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "\n",
    "    for threshold in np.arange(0.1, 0.5, 0.01):\n",
    "        binary_mask = (mask > threshold).astype(np.uint8) * 255  # Binarisieren und in 8-bit konvertieren\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            avg_size = calculate_average_contour_size(largest_contour)\n",
    "            score = avg_size  # Anpassen der Bewertungsmetrik nach Bedarf\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(model_path_1)\n",
    "\n",
    "\n",
    "\n",
    "# Listen für die berechneten Durchmesser und die manuell gemessenen Durchmesser\n",
    "manual_diameters = []\n",
    "\n",
    "# Iteration über alle TIFF-Dateien im Eingabeordner\n",
    "tif_files = [f for f in os.listdir(input_dir) if f.endswith('.tif')]\n",
    "\n",
    "# Debug-Ausgabe: Anzahl der TIFF-Dateien\n",
    "print(f\"Anzahl der TIFF-Dateien: {len(tif_files)}\")\n",
    "\n",
    "# Überprüfen, ob die Anzahl der Dateien mit der Anzahl der manuellen Messungen übereinstimmt\n",
    "if len(tif_files) != len(df_manual):\n",
    "    print(\"Die Anzahl der Bilddateien stimmt nicht mit der Anzahl der manuellen Messungen überein.\")\n",
    "else:\n",
    "    for i, filename in enumerate(tif_files):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Bild laden und vorverarbeiten\n",
    "            image = load_and_preprocess_image_pillow(img_path)\n",
    "            # Vorhersage mit dem Modell machen\n",
    "            predicted_mask = predict_with_model(model, image)\n",
    "            if predicted_mask is None:\n",
    "                print(f\"Fehler bei der Vorhersage für {filename}.\")\n",
    "                continue\n",
    "\n",
    "            # Besten Schwellenwert für Konturen finden\n",
    "            best_threshold = find_best_threshold(predicted_mask)\n",
    "\n",
    "            # Maske mit dem besten Schwellenwert erstellen\n",
    "            binary_mask = (predicted_mask > best_threshold).astype(np.uint8) * 255  # Binarisieren und in 8-bit konvertieren\n",
    "            \n",
    "            # Konturen finden\n",
    "            contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            if not contours:\n",
    "                print(f\"Keine Konturen im Bild {filename} gefunden.\")\n",
    "                continue\n",
    "\n",
    "            # Filtere Konturen nach Schmalheitsverhältnis\n",
    "            filtered_contours = []\n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                perimeter = cv2.arcLength(contour, True)\n",
    "                if perimeter == 0:\n",
    "                    continue\n",
    "                circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "                if circularity > 0.5:  # Anpassen des Schmalheitsverhältnisses nach Bedarf\n",
    "                    filtered_contours.append(contour)\n",
    "\n",
    "            if not filtered_contours:\n",
    "                print(f\"Keine geeigneten Konturen im Bild {filename} gefunden.\")\n",
    "                continue\n",
    "\n",
    "            # Die größte Kontur nach dem Flächeninhalt finden\n",
    "            largest_contour = max(filtered_contours, key=cv2.contourArea)\n",
    "\n",
    "            # Berechne den Schwerpunkt der Kontur\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] == 0:\n",
    "                print(f\"Schwerpunkt konnte im Bild {filename} nicht berechnet werden.\")\n",
    "                continue\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "            # Berechne den mittleren Durchmesser\n",
    "            avg_diameter_pixels = calculate_average_diameter(largest_contour, center)\n",
    "            avg_diameter_micrometers = avg_diameter_pixels * (0.3745 * scale_factor_width)\n",
    "\n",
    "            # Berechnung des Flächeninhalts\n",
    "            area_pixels = cv2.contourArea(largest_contour)\n",
    "            area_micrometers = area_pixels * (0.3745 * scale_factor_width * 0.3745 * scale_factor_height)\n",
    "\n",
    "            # Ergebnisse hinzufügen\n",
    "            predicted_diameters.append(avg_diameter_micrometers)\n",
    "            manual_diameters.append(df_manual.iloc[i, 0])  # Manuell gemessener Durchmesser hinzufügen\n",
    "\n",
    "            # Ausgabepfad für das segmentierte Bild definieren\n",
    "            output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_segmentiert.tif\")\n",
    "            # Maske als TIFF-Datei speichern\n",
    "            Image.fromarray(binary_mask, mode='L').save(output_path)\n",
    "            print(f\"Segmentiertes Bild für {filename} wurde gespeichert.\")\n",
    "\n",
    "            # Ergebnisse ausgeben\n",
    "            print(f\"Bild: {filename}, Durchmesser: {avg_diameter_micrometers:.2f} µm, Flächeninhalt: {area_micrometers:.2f} µm²\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei der Verarbeitung von {filename}: {e}\")\n",
    "\n",
    "    # Debug-Ausgabe: Anzahl der erfolgreichen Vorhersagen und manuell gemessenen Durchmesser\n",
    "    print(f\"Anzahl der erfolgreichen Vorhersagen: {len(predicted_diameters)}\")\n",
    "    print(f\"Anzahl der zugehörigen manuellen Durchmesser: {len(manual_diameters)}\")\n",
    "\n",
    "    # Ergebnisse in ein DataFrame konvertieren\n",
    "    df_results = pd.DataFrame({\n",
    "        'Manuell gemessene Durchmesser (µm)': manual_diameters,\n",
    "        'Vorhergesagte Durchmesser (µm)': predicted_diameters\n",
    "    })\n",
    "\n",
    "    # Ergebnisse in eine Excel-Datei exportieren\n",
    "    df_results.to_excel(excel_output_path_1, index=False)\n",
    "\n",
    "        # Berechnung der Metriken zur Bewertung der Modellgenauigkeit\n",
    "    if len(predicted_diameters) > 0 and len(manual_diameters) > 0:\n",
    "        mae = mean_absolute_error(manual_diameters, predicted_diameters)\n",
    "        mse = mean_squared_error(manual_diameters, predicted_diameters)\n",
    "        r2 = r2_score(manual_diameters, predicted_diameters)\n",
    "\n",
    "        print(f\"\\nMetriken zur Bewertung der Modellgenauigkeit:\")\n",
    "        print(f\"MAE (Mean Absolute Error): {mae:.2f} µm\")\n",
    "        print(f\"MSE (Mean Squared Error): {mse:.2f} µm²\")\n",
    "        print(f\"R2 Score (Coefficient of Determination): {r2:.2f}\")\n",
    "\n",
    "        print(f\"Ergebnisse und Metriken wurden in {excel_output_path_1} gespeichert.\")\n",
    "    else:\n",
    "        print(\"Keine ausreichenden Daten zur Berechnung der Metriken vorhanden.\")\n",
    "\n",
    "    # Scatterplot erstellen\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(manual_diameters, predicted_diameters, color='blue', label='Vorhergesagt vs. Manuell')\n",
    "    plt.plot([min(manual_diameters), max(manual_diameters)], [min(manual_diameters), max(manual_diameters)], color='red', linestyle='--', label='Perfekte Übereinstimmung')\n",
    "    plt.xlabel('Manuell gemessene Durchmesser (µm)')\n",
    "    plt.ylabel('Vorhergesagte Durchmesser (µm)')\n",
    "    plt.title('Vergleich von manuellen und vorhergesagten Durchmessern')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('C:/Users/chris/Documents/Master/Sphaeroidauswertung/Ergebnisse/scatterplot_neu.png')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
